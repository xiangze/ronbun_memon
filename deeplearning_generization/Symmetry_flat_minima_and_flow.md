# Symmetries, flat minima, and the conserved quantities of gradient flow

DNNの損失状況に関する実証研究により、多くの極小値が低損失の谷を介して接続されていることが明らかになりました。
しかし、そのような谷の理論的起源についてはほとんど知られていません。
我々は、低損失の谷を形成するパラメータ空間内の連続対称性を見つけるための一般的なフレームワークを提示します。
私たちのフレームワークは活性化関数の等価性を使用しており、さまざまな層アーキテクチャに適用できます。このフレームワークを非線形NNに一般化するために、新しい一連の非線形のデータ依存対称性を導入します。

これらの対称性により、新しいサンプルでも同様に動作するように訓練済みモデルを変換することができ、これにより、特定の敵対的な攻撃に対する堅牢性を向上させるアンサンブルの構築が可能になります。

次に、線形対称性に関連する保存量を使用して、低損失の谷に沿った座標を定義できることを示します。保存された量は、一般的な初期化方法を使用すると、勾配流が大域最小値のごく一部のみを探索することを明らかにするのに役立ちます。保存量を収束率と最小値の鋭さに関連付けることにより、初期化が収束と一般化可能性にどのような影響を与えるかについての洞察が得られます。

https://arxiv.org/abs/2210.17216

## キーワード
保存量(CQ),対称性, ネーターの定理,勾配流, 初期値

## イントロ

DNNの学習は、高度に非凸な最適化問題である。モデルのアーキテクチャとデータセットによって形成されるNNの損失ランドスケープは、一般的に非常に荒く、ローカルミニマムの数はモデルサイズに応じて急速に増加する（Bray & Dean, 2007; S¸ims¸ek et al.、2021）。このような複雑さにもかかわらず、最近の研究では、損失ランドスケープに多くの興味深い構造があることが明らかになっている。例えば、NNの損失ランドスケープは、損失が大きく変化しないほぼフラットな方向を含むことが多い（Freeman & Bruna, 2017; Garipov et al., 2018）。平坦な最小値は、同様の損失値をもたらす異なるパラメータ構成をサンプリングすることにより、アンサンブルモデルや混合モデルを構築するために使用されてきた（Garipov et al., 2018; Benton et al., 2021）。しかし、そのようなフラットな方向を見つけることは、ほとんどが経験的に行われており、理論的な結果はほとんどありません。フラットな方向性の1つの源は**損失を不変に保つパラメータ変換（すなわち対称性）**である。具体的には、対称性のある方向の最小値からパラメータ空間内を移動すると の方向に最小値から移動すると、別の最小値へ移動する。損失の連続的な対称性は、局所的な最小値において平坦な方向をもたらすという事実に動機づけられた。この論文では、このような対称性の一般的なクラスを導出する。


1. NN損失ランドスケープにおける対称性を見出すための等価性に基づく一般的なフレームワーク
2. 対称性によって引き起こされる**極小値の次元**の導出
3. NNパラメータ空間の非線形、データ依存の対称性の新しいクラス
4. 対称性に関連する保存量(CQ)の導出に関する先行研究の拡張と、回転対称性についての失敗についての議論
5. 回転対称性の層間における角運動量の相殺の結果
6. 対称性に起因するフラットミニマムのパラメタリゼーション



## 関連研究


## 3 CONTINUOUS SYMMETRIES IN DEEP LEARNING
変換群
活性化関数の取扱
## 4 NONLINEAR DATA-DEPENDENT SYMMETRIES

## 5 保存量と勾配流

θ˙(t) = dθ(t)/dt = −ε∇_{θ(t)} L

<ε^{ −1}\dot{θ} ,M · θ >= 0

Noether’s theorem.

## 6 応用


## 7 ディスカッション


## 感想

- 理論的解析
- 対称性が重要というのは新しい視点で、納得が行く。
- 画像のような対称性を持ったデータ、CNNや個別の対称性を保つネットワーク研究に適応した時主張できることがありそう。
→鏡映変換は離散群では？
- 対称性が重要なのはヘテロクリニック軌道またはそれが分岐したものなのかもしれない。それはどのようにして証明することができるか。
- 生物系、進化系の方の特定のモデルとの等価性、類似性から対称性についてなんか言えないか
